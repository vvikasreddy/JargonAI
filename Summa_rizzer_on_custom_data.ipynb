{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vvikasreddy/JargonAI/blob/main/Summa_rizzer_on_custom_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJCguv5rm6ot",
        "outputId": "05ba3e7a-caa9-462b-e80b-64f4e29ed168"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AdamW\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "metadata": {
        "id": "B0VJF5kwoN_f"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the dataset\n",
        "dataset_path = \"/content/Corpus_all.csv\"\n",
        "# try:\n",
        "#     data = pd.read_csv(dataset_path, encoding=\"utf-8\")\n",
        "# except UnicodeDe|codeError:\n",
        "#\n",
        "data = pd.read_csv(dataset_path, encoding=\"ISO-8859-1\")\n",
        "# data.drop()"
      ],
      "metadata": {
        "id": "NaRvpZbhnpXw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.iloc[38]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "HKKQ5_4xeL6f",
        "outputId": "dd6821bc-4780-4846-b217-c782ff2e44c4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document    The County Council of West Midlands (M6 Motorw...\n",
              "Summary     The County Council of West Midlands (M6 Motorw...\n",
              "Name: 38, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>38</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Document</th>\n",
              "      <td>The County Council of West Midlands (M6 Motorw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Summary</th>\n",
              "      <td>The County Council of West Midlands (M6 Motorw...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wR7iMThepL-C",
        "outputId": "6306580e-d737-4502-ddb3-28ace5e25d83"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            Document  \\\n",
            "0  412.106.1 English is not an official language ...   \n",
            "1  944.021.1 English is not an official language ...   \n",
            "2  Title and commencement 1 This order may be cit...   \n",
            "3  Citation and commencement 1 This order may be ...   \n",
            "4  Title, commencement and interpretation 1 1 Thi...   \n",
            "\n",
            "                                             Summary  \n",
            "0  The Swiss Federal University for Vocational Ed...  \n",
            "1  The EAER Ordinance on the Declaration for Timb...  \n",
            "2  The North West Water Authority (Solway Firth) ...  \n",
            "3  The Trafford Park Development Corporation (Are...  \n",
            "4  The North West Water Authority (Returns of Eel...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#extract documents and summaries\n",
        "data = data.dropna(subset=[\"Document\", \"Summary\"])#ensure no missing values\n",
        "data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "input_texts = data[\"Document\"].tolist()\n",
        "target_texts = data[\"Summary\"].tolist()"
      ],
      "metadata": {
        "id": "2Ip6PiVDnu0k"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_texts[0])\n",
        "print(target_texts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9PrfHiJpa_i",
        "outputId": "3b895c84-bbb9-407c-f5d5-81bdec2c22f0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "412.106.1 English is not an official language of the Swiss Confederation. This translation is provided for information purposes only, has no legal force and may not be relied on in legal proceedings. Ordinance on the Swiss Federal University for Vocational Education and Training(SFUVET Ordinance)of 18 June 2021 (Status as of 1 August 2021)The Swiss Federal Council,on the basis of Article 35 of the SFUVET Act of 25 September 20201,ordains:1 SR 412.106Art. 1 Registered location The Swiss Federal University for Vocational Education and Training (SFUVET) shall be based in Zollikofen.Art. 2 Regional campuses SFUVET shall offer its services through three regional campuses: one in the German-speaking region, one in the French-speaking region and one in the Italian-speaking region of Switzerland.Art. 3 Federal Council's strategic objectives The Federal Department of Economic Affairs, Education and Research (EAER) shall submit SFUVET's strategic objectives drafted by the Federal Council to the following national umbrella organisations for consultation: the Swiss Union of Crafts and Small and Medium-sized Enterprises (SGV), the Swiss Employers' Association (SAV), the Swiss Trade Union Confederation (SGB) and Travail Suisse.Art. 4 SFUVET partnership dynamics with professional organisations and cantonal authorities 1 SFUVET shall involve professional organisations and the cantonal authorities in its strategic planning activities, in the planning of new training courses and services, and in the creation of research areas.2 It may form national and regional advisory boards comprising representatives of professional organisations, cantonal authorities and other interested parties.Art. 5 Repeal and amendment of current legislation 1 The SFIVET Ordinance of 14 September 20052 is repealed.2 ...32 [AS 2005 4607; 2009 5933; 2016 575]3 The amendments may be consulted under AS 2021 405.Art. 6 Transitional provisions Articles 16 and 16a of the SFIVET Ordinance of 14 September 20054 shall remain in force until 31 December 2021.4 AS 2016 575Art. 7 Commencement 1 Subject to paragraph 2, this Ordinance comes into force on 1 August 2021.2 Article 5 paragraph 2 comes into force on 1 January 2022.\n",
            "The Swiss Federal University for Vocational Education and Training (SFUVET) is based in Zollikofen and has 3 campuses in Switzerland. These campuses are separated by the language spoken in the region, which are German, French, and Italilan. It colabortates with industry groups and regional authorities to plan courses, services, and research. The government sets their goals and consults with national organikzations like trade unions and employers associations. Old rules have been replaced on August 1, 2021, but a few parts will continue to be active until the end of 2021.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlOKVeAPnz4s",
        "outputId": "5d251233-c1bb-4c50-ef34-65d605a3dd3a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define the custom dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, tokenizer, input_texts, target_texts, max_input_length=512, max_target_length=128):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.input_texts = input_texts\n",
        "        self.target_texts = target_texts\n",
        "        self.max_input_length = max_input_length\n",
        "        self.max_target_length = max_target_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_encoding = self.tokenizer(\n",
        "            self.input_texts[idx],\n",
        "            max_length=self.max_input_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        target_encoding = self.tokenizer(\n",
        "            self.target_texts[idx],\n",
        "            max_length=self.max_target_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": input_encoding[\"input_ids\"].squeeze(),\n",
        "            \"attention_mask\": input_encoding[\"attention_mask\"].squeeze(),\n",
        "            \"labels\": target_encoding[\"input_ids\"].squeeze(),\n",
        "        }\n",
        "\n"
      ],
      "metadata": {
        "id": "o1NKTA51n4M3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "train_input_texts, test_input_texts, train_target_texts, test_target_texts = train_test_split(\n",
        "    input_texts, target_texts, test_size=0.1, random_state=42\n",
        ")\n",
        "\n",
        "# Create datasets for train, validation, and test\n",
        "train_dataset = CustomDataset(tokenizer, train_input_texts, train_target_texts)\n",
        "test_dataset = CustomDataset(tokenizer, test_input_texts, test_target_texts)\n",
        "\n",
        "batch_size = 32\n",
        "# Create DataLoaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=1 shuffle=False)\n"
      ],
      "metadata": {
        "id": "egfSUwfvQu8A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "352da4a1-0a0a-4c91-e731-1032cf209155"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax. Perhaps you forgot a comma? (<ipython-input-26-a5d300f662fc>, line 15)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-26-a5d300f662fc>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    test_dataloader = DataLoader(test_dataset, batch_size=1 shuffle=False)\u001b[0m\n\u001b[0m                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#set up training\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSN856rPn7pV",
        "outputId": "7c74af6c-5574-4293-de71-9225fba9b552"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training loop\n",
        "from tqdm import tqdm\n",
        "\n",
        "loss = float('inf')\n",
        "\n",
        "epochs = 50\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "    epoch_loss = 0\n",
        "    for batch in tqdm(train_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / len(train_dataloader)}\")\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            val_loss += loss.item()\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss / len(test_dataloader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqmGOqi7n_m1",
        "outputId": "04d07e3d-585d-4c68-d87d-72f551ebb84b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 2.9415303468704224\n",
            "Epoch 1/50, Validation Loss: 2.383004903793335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/50, Loss: 1.9736133217811584\n",
            "Epoch 2/50, Validation Loss: 2.3756473064422607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/50, Loss: 1.9732563495635986\n",
            "Epoch 3/50, Validation Loss: 2.370236396789551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/50, Loss: 1.9372682571411133\n",
            "Epoch 4/50, Validation Loss: 2.3660833835601807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/50, Loss: 1.9125086665153503\n",
            "Epoch 5/50, Validation Loss: 2.3624026775360107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/50, Loss: 1.878647267818451\n",
            "Epoch 6/50, Validation Loss: 2.359581232070923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/50, Loss: 1.8514996767044067\n",
            "Epoch 7/50, Validation Loss: 2.3576343059539795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/50, Loss: 1.846783697605133\n",
            "Epoch 8/50, Validation Loss: 2.3534963130950928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/50, Loss: 1.8154012560844421\n",
            "Epoch 9/50, Validation Loss: 2.3472797870635986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/50, Loss: 1.7725217938423157\n",
            "Epoch 10/50, Validation Loss: 2.3426589965820312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/50, Loss: 1.7509711980819702\n",
            "Epoch 11/50, Validation Loss: 2.3412961959838867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/50, Loss: 1.71368408203125\n",
            "Epoch 12/50, Validation Loss: 2.340348958969116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/50, Loss: 1.707790493965149\n",
            "Epoch 13/50, Validation Loss: 2.3384289741516113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/50, Loss: 1.665384590625763\n",
            "Epoch 14/50, Validation Loss: 2.3365609645843506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/50, Loss: 1.6427425146102905\n",
            "Epoch 15/50, Validation Loss: 2.3358962535858154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/50, Loss: 1.6162269711494446\n",
            "Epoch 16/50, Validation Loss: 2.3363149166107178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/50, Loss: 1.600816547870636\n",
            "Epoch 17/50, Validation Loss: 2.3379790782928467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/50, Loss: 1.5646567940711975\n",
            "Epoch 18/50, Validation Loss: 2.3398358821868896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/50, Loss: 1.5315228700637817\n",
            "Epoch 19/50, Validation Loss: 2.3416521549224854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/50, Loss: 1.5183596014976501\n",
            "Epoch 20/50, Validation Loss: 2.3439078330993652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/50, Loss: 1.4946388602256775\n",
            "Epoch 21/50, Validation Loss: 2.346719980239868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/50, Loss: 1.4504199624061584\n",
            "Epoch 22/50, Validation Loss: 2.3504505157470703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/50, Loss: 1.4325153231620789\n",
            "Epoch 23/50, Validation Loss: 2.354902505874634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/50, Loss: 1.4189943671226501\n",
            "Epoch 24/50, Validation Loss: 2.359973430633545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/50, Loss: 1.3927991390228271\n",
            "Epoch 25/50, Validation Loss: 2.36625075340271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/50, Loss: 1.3539064526557922\n",
            "Epoch 26/50, Validation Loss: 2.3734352588653564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/50, Loss: 1.3457267880439758\n",
            "Epoch 27/50, Validation Loss: 2.3823611736297607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/50, Loss: 1.294267177581787\n",
            "Epoch 28/50, Validation Loss: 2.3912618160247803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/50, Loss: 1.2687694430351257\n",
            "Epoch 29/50, Validation Loss: 2.4010090827941895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/50, Loss: 1.2599875926971436\n",
            "Epoch 30/50, Validation Loss: 2.412480115890503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/50, Loss: 1.2196197509765625\n",
            "Epoch 31/50, Validation Loss: 2.42429256439209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32/50, Loss: 1.2092599272727966\n",
            "Epoch 32/50, Validation Loss: 2.4366908073425293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33/50, Loss: 1.1702561974525452\n",
            "Epoch 33/50, Validation Loss: 2.451190233230591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34/50, Loss: 1.147973120212555\n",
            "Epoch 34/50, Validation Loss: 2.467395544052124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35/50, Loss: 1.1214123964309692\n",
            "Epoch 35/50, Validation Loss: 2.4830710887908936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36/50, Loss: 1.0856226682662964\n",
            "Epoch 36/50, Validation Loss: 2.501483678817749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37/50, Loss: 1.0656485557556152\n",
            "Epoch 37/50, Validation Loss: 2.5257654190063477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38/50, Loss: 1.0415123105049133\n",
            "Epoch 38/50, Validation Loss: 2.5485429763793945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39/50, Loss: 1.0081251859664917\n",
            "Epoch 39/50, Validation Loss: 2.569274663925171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40/50, Loss: 0.984700471162796\n",
            "Epoch 40/50, Validation Loss: 2.5890233516693115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41/50, Loss: 0.9549252390861511\n",
            "Epoch 41/50, Validation Loss: 2.609323740005493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42/50, Loss: 0.9092594385147095\n",
            "Epoch 42/50, Validation Loss: 2.632584810256958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43/50, Loss: 0.8832935094833374\n",
            "Epoch 43/50, Validation Loss: 2.6597938537597656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44/50, Loss: 0.8468686938285828\n",
            "Epoch 44/50, Validation Loss: 2.689117670059204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45/50, Loss: 0.8174607157707214\n",
            "Epoch 45/50, Validation Loss: 2.7176456451416016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46/50, Loss: 0.7947088778018951\n",
            "Epoch 46/50, Validation Loss: 2.745414972305298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47/50, Loss: 0.7658650279045105\n",
            "Epoch 47/50, Validation Loss: 2.774783134460449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48/50, Loss: 0.7354615032672882\n",
            "Epoch 48/50, Validation Loss: 2.8049659729003906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49/50, Loss: 0.7090731561183929\n",
            "Epoch 49/50, Validation Loss: 2.838202714920044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/50, Loss: 0.6863137185573578\n",
            "Epoch 50/50, Validation Loss: 2.8721208572387695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation\n",
        "def evaluate_model(dataset, tokenizer, model):\n",
        "    model.eval()\n",
        "    #dataloader = DataLoader(dataset, batch_size=16)\n",
        "    predictions = []\n",
        "    references = []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "            outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_new_tokens=256)\n",
        "            predictions.extend(tokenizer.batch_decode(outputs, skip_special_tokens=True))\n",
        "            references.extend([tokenizer.decode(ref, skip_special_tokens=True) for ref in batch[\"labels\"]])\n",
        "    return predictions, references"
      ],
      "metadata": {
        "id": "sUFbNh_koCnV"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run evaluation\n",
        "predictions, references = evaluate_model(test_dataset, tokenizer, model)"
      ],
      "metadata": {
        "id": "KzY_a3HToIME",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d265b5b2-5f82-4286-f6c1-5852dc28b310"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 1/1 [00:03<00:00,  3.64s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "iqQ94mMdVWkS",
        "outputId": "30b05a82-7e24-4e91-f579-0f413c6bb31b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The Federal Assembly of the Swiss Confederation,the Federal Assembly of the Swiss Confederation,considered the Federal Council Dispatch on 18 August 20102,decrees:SR 1012 BBl 2010 5549Art. Subject of recognition The Federal Council is authorised to recognise agreements between private institutions for the avoidance of double taxation with respect to taxes on income and capital, provided the conclusion of an international treaty on the same issue is not an option.Art. Requirements The recognition of an agreement requires that the agreement is compatible with Switzerland's agreement policy for the avoidance of double taxation; if the agreement has been infringed in a serious manner; orc.withdrawal recognition is required to safeguard Switzerland's interests.The agreement is published with the decision on recognition. The referendum is scheduled for the 15 November 2011 and is a referendum.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "references[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "cU86jOxtYDcd",
        "outputId": "33e3a058-adb0-45ea-9a71-1caf7e1cc988"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This Act grants the Federal Council the authority to recognize private agreements between institutions for the avoidance of double taxation on income and capital, when an international treaty on the same issue is not feasible. Recognition of such agreements requires reciprocity, alignment with Switzerlands tax policy, and approval from both the National Council and the Council of States. The Federal Council may withdraw recognition if reciprocity is no longer guaranteed, if the agreement is seriously violated, or if withdrawal is necessary to protect Switzerlands interests. Once recognized, the agreement applies nationwide. The decision and the agreement are published in the Federal Gazette.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score\n",
        "!pip install bert_score\n"
      ],
      "metadata": {
        "id": "hphtlParYGvu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d938805-6f2c-4417-894e-25f2c7af7c45"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.67.1)\n",
            "Requirement already satisfied: bert_score in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.5.1+cu121)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.2.2)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.47.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert_score) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert_score) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert_score) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2024.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.27.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.4.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2024.12.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from rouge_score import rouge_scorer\n",
        "from bert_score import score as bert_score\n",
        "\n",
        "# Calculate ROUGE Scores\n",
        "def calculate_rouge(predictions, references):\n",
        "    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
        "    rouge_scores = {\"rouge1\": [], \"rouge2\": [], \"rougeL\": []}\n",
        "    for ref, pred in zip(references, predictions):\n",
        "\n",
        "        scores = scorer.score(ref, pred)\n",
        "        for key in rouge_scores:\n",
        "            rouge_scores[key].append(scores[key].fmeasure)\n",
        "    return {key: sum(values) / len(values) for key, values in rouge_scores.items()}\n",
        "\n",
        "rouge_scores = calculate_rouge(predictions, references)\n",
        "print(f\"ROUGE Scores: {rouge_scores}\")\n",
        "\n",
        "# Calculate BERT Scores\n",
        "def calculate_bert_score(predictions, references):\n",
        "    P, R, F1 = bert_score(predictions, references, model_type=\"bert-base-uncased\", lang=\"en\")\n",
        "    return {\n",
        "        \"Precision\": P.mean().item(),\n",
        "        \"Recall\": R.mean().item(),\n",
        "        \"F1\": F1.mean().item()\n",
        "    }\n",
        "\n",
        "bert_scores = calculate_bert_score(predictions, references)\n",
        "print(f\"BERT Scores: {bert_scores}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7eyY7bXZv2N",
        "outputId": "b738f50c-2d45-4040-c4d1-0ee98cf7d320"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE Scores: {'rouge1': 0.35677993516392836, 'rouge2': 0.12389001827567678, 'rougeL': 0.2454581578327401}\n",
            "BERT Scores: {'Precision': 0.6105272173881531, 'Recall': 0.5724552273750305, 'F1': 0.5900307893753052}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "# Set the desired line width\n",
        "line_width = 145  # Adjust this as needed for your screen\n",
        "\n",
        "for indx, val in enumerate(predictions):\n",
        "    print(f\"Reference {indx + 1}:\\n{textwrap.fill(references[indx], width=line_width)}\")\n",
        "    print(f\"Prediction {indx + 1}:\\n{textwrap.fill(val, width=line_width)}\")\n",
        "    print(\"-\" * 30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhWlul0vaPsD",
        "outputId": "85a95d85-11a1-41c7-d7cb-c08dc41ca514"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reference 1:\n",
            "The Swiss Federal University for Vocational Education and Training (SFUVET) is based in Zollikofen and has 3 campuses in Switzerland. These\n",
            "campuses are separated by the language spoken in the region, which are German, French, and Italilan. It colabortates with industry groups and\n",
            "regional authorities to plan courses, services, and research. The government sets their goals and consults with national organikzations like\n",
            "trade unions and employers associations. Old rules have been replaced on August 1, 2021, but a few parts will continue to be active until the end\n",
            "of 2021.\n",
            "Prediction 1:\n",
            "The SFUVET Ordinance is established on June 18, 2020. It meets with national and regional advisory boards, planning training courses, and other\n",
            "relevant research areas. Its strategic objectives include a coordinated approach to strategic planning, training development, training\n",
            "development, and the establishment of research and development facilities. Its mandated transitional provisions, including repealing them, are in\n",
            "place during these provisions. The SFIVET Ordinance is enacted on August 1, 2005.\n",
            "------------------------------\n",
            "Reference 2:\n",
            "The Data Protection (Miscellaneous Subject Access Exemptions) Order 1987 exempts certain personal data from the right of access under Part IV of\n",
            "the Data Protection Act 1984. This applies to data where disclosure is restricted or prohibited by specific laws listed in the schedule to the\n",
            "order. These restrictions are intended to protect the interests of individuals or others. The order comes into effect on November 11, 1987.\n",
            "Prediction 2:\n",
            "The Data Protection (Miscellaneous Subject Access Exemptions) Order 1987 allows restricted access to personal data relating to those data deemed\n",
            "prohibited or restricted. This includes disclosures of sensitive and/or non-disclosured information. This includes disclosures of sensitive\n",
            "and/or nondisclosured data. This includes disclosures of sensitive and nondisclosured data. This includes disclosures of sensitive and\n",
            "nondisclosured information. This includes disclosures of sensitive and nondisclosured information.\n",
            "------------------------------\n",
            "Reference 3:\n",
            "Article 120 states that discussions in Parliament shall be conducted in Hindi or English. However, members may use their mother tongue with the\n",
            "Speaker's permission. The use of English can be discontinued 15 years after the Constitution's commencement unless Parliament decides otherwise.\n",
            "Article 121 prohibits discussions in Parliament that condemn the conduct of judges in the discharge of their duties. Article 122 states that\n",
            "courts cannot question the use of powers granted by the Constitution to regulate parliamentary procedures or maintain order. Article 123 empowers\n",
            "the President to pass ordinances when both Houses are not in session, provided urgent action is required.\n",
            "Prediction 3:\n",
            "The use of English language in Parliament is governed by laws XVII, and business is transacted in Hindi or English, if Parliament is otherwise\n",
            "lawful. The address should be given to the President, and the President can present an address to the President, if both houses of parliament are\n",
            "in session, the President may promulgate such ordinances as he desires. If both houses are in session, the President can immediately take action\n",
            "by presiding over such ordinances as he desires.\n",
            "------------------------------\n",
            "Reference 4:\n",
            "The Commission Decision (Case M.7542 - GRIFFIN / SKANSKA / STARWOOD / HOTEL ATRIUM), dated November 26, 2015, approved a joint acquisition of\n",
            "Hotel Atrium sp. z o.o. (owner of the Westin Warsaw hotel) by Griffin, Skanska, and Starwood. Griffin, part of the Oaktree Capital Group,\n",
            "specializes in real estate investments in Central and Eastern Europe. Skanska focuses on real estate development and construction services, while\n",
            "Starwood is a global\n",
            "Prediction 4:\n",
            "The European Commission decided to take a look at the case M.7542 - GRIFFIN / SKANSKA / Starwood / HOTEL ATRIUM Commission decision pursuant to\n",
            "Article 6(1)(b) of Council Regulation (EC) No 139/2004[1] and Article 57 of the Agreement on the European Economic Area[2]\n",
            "------------------------------\n",
            "Reference 5:\n",
            "Each state will have a governor, and the same person can be appointed as the governor for more than one state. The executive power of the state\n",
            "lies with the governor, who exercises it in accordance with the states constitution. This does not mean that the governor will take over\n",
            "responsibilities already assigned to other authorities by existing laws, nor does it prevent Parliament or the state legislature from giving\n",
            "tasks to other authorities. The governor is appointed by the President through a warrant under his hand and seal. The governor holds the position\n",
            "at the President's discretion and can resign by writing to the President. The governor'\n",
            "Prediction 5:\n",
            "The governor of two states must be appointed by the President, and he must resign by writing to the President. The governor may resign by writing\n",
            "to the president, if he resigns, and if he s not a citizen of India, resigns by writing to the president. The governor may resign by writing to\n",
            "the president, if he s not a citizen of India, or if he s a citizen of another country, resign by writing to the president.\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in references:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A98sZyUAgspZ",
        "outputId": "8a4d34ee-5cdb-4be1-f836-17fe3ff62df9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Swiss Federal University for Vocational Education and Training (SFUVET) is based in Zollikofen and has 3 campuses in Switzerland. These campuses are separated by the language spoken in the region, which are German, French, and Italilan. It colabortates with industry groups and regional authorities to plan courses, services, and research. The government sets their goals and consults with national organikzations like trade unions and employers associations. Old rules have been replaced on August 1, 2021, but a few parts will continue to be active until the end of 2021.\n",
            "The Data Protection (Miscellaneous Subject Access Exemptions) Order 1987 exempts certain personal data from the right of access under Part IV of the Data Protection Act 1984. This applies to data where disclosure is restricted or prohibited by specific laws listed in the schedule to the order. These restrictions are intended to protect the interests of individuals or others. The order comes into effect on November 11, 1987.\n",
            "This Act grants the Federal Council the authority to recognize private agreements between institutions for the avoidance of double taxation on income and capital, when an international treaty on the same issue is not feasible. Recognition of such agreements requires reciprocity, alignment with Switzerlands tax policy, and approval from both the National Council and the Council of States. The Federal Council may withdraw recognition if reciprocity is no longer guaranteed, if the agreement is seriously violated, or if withdrawal is necessary to protect Switzerlands interests. Once recognized, the agreement applies nationwide. The decision and the agreement are published in the Federal Gazette.\n",
            "Article 120 states that discussions in Parliament shall be conducted in Hindi or English. However, members may use their mother tongue with the Speaker's permission. The use of English can be discontinued 15 years after the Constitution's commencement unless Parliament decides otherwise. Article 121 prohibits discussions in Parliament that condemn the conduct of judges in the discharge of their duties. Article 122 states that courts cannot question the use of powers granted by the Constitution to regulate parliamentary procedures or maintain order. Article 123 empowers the President to pass ordinances when both Houses are not in session, provided urgent action is required.\n",
            "The Commission Decision (Case M.7542 - GRIFFIN / SKANSKA / STARWOOD / HOTEL ATRIUM), dated November 26, 2015, approved a joint acquisition of Hotel Atrium sp. z o.o. (owner of the Westin Warsaw hotel) by Griffin, Skanska, and Starwood. Griffin, part of the Oaktree Capital Group, specializes in real estate investments in Central and Eastern Europe. Skanska focuses on real estate development and construction services, while Starwood is a global\n",
            "Each state will have a governor, and the same person can be appointed as the governor for more than one state. The executive power of the state lies with the governor, who exercises it in accordance with the states constitution. This does not mean that the governor will take over responsibilities already assigned to other authorities by existing laws, nor does it prevent Parliament or the state legislature from giving tasks to other authorities. The governor is appointed by the President through a warrant under his hand and seal. The governor holds the position at the President's discretion and can resign by writing to the President. The governor'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(predictions[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax4vtGnLgvoZ",
        "outputId": "a91d01c1-390f-4f4f-e4da-e0b56cf6ffec"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "127"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qEkLWI2HhduH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}